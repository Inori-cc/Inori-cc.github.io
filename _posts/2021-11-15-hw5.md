---
layout: post
title:  "Homework 5"
date:   2021-11-15
excerpt: "Dive into Deep Learning"
tag: [post]
comments: true
---

##  HW5. Dive into Deep Learning
Train a deep learning model to classify beetles, cockroaches and dragonflies using these [images](https://www.dropbox.com/s/fn73sj2e6c9rhf6/insects.zip?dl=0). Note: Original images from <https://www.insectimages.org/index.cfm>. Blog about this, and explain how the neural network classified the images using [SHapley Additive exPlanations](https://github.com/slundberg/shap).

### Load libraries
```
import PIL
from PIL import Image
import glob
import os
import matplotlib.pyplot as plt
import numpy as np
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from tensorflow.keras.models import Sequential
import shap
```

### Load training set (including validation set) and test set
Set default values.
```
batch_size = 32
img_height = 180
img_width = 180
```
Training set (80%):
```
ds_train = tf.keras.utils.image_dataset_from_directory(
  'insects/train/',
  validation_split=0.2,
  subset="training",
  seed =123,
  image_size=(img_height, img_width),
  batch_size=batch_size)
```
```
>>> Found 1019 files belonging to 3 classes.
Using 816 files for training.
```
Class names:
```
class_names = ds_train.class_names
class_names
```
```
>>> ['beetles', 'cockroach', 'dragonflies']
```
Validation set (20%):
```
ds_val = tf.keras.utils.image_dataset_from_directory(
  'insects/train/',
  validation_split=0.2,
  subset="validation",
  seed =123,
  image_size=(img_height, img_width),
  batch_size=batch_size)
```
```
>>> Found 1019 files belonging to 3 classes.
Using 203 files for validation.
```
Test set:
```
ds_test = tf.keras.utils.image_dataset_from_directory(
  'insects/test/',
  seed =123,
  image_size=(img_height, img_width),
  batch_size=batch_size)
```
```
>>> Found 180 files belonging to 3 classes.
```

### Load images & visual effect check
Load three images
```
plt.figure(figsize=(12, 12))
for images, labels in ds_train.take(1):
    for i in range(3):
        ax = plt.subplot(1, 3, i + 1)
        plt.imshow(images[i].numpy().astype("uint8"))
        plt.axis("off")
        plt.title(class_names[labels[i]])
```
![Image 1](/v_source/hw5-1.png)
```
for image_batch, labels_batch in ds_train:
    print(image_batch.shape)
    print(labels_batch.shape)
    break
```
```
>>> (32, 180, 180, 3)
>>> (32,)
```

### Better performance
```
AUTOTUNE = tf.data.AUTOTUNE

ds_train = ds_train.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)
ds_val = ds_val.cache().prefetch(buffer_size=AUTOTUNE)
```

### Standardization
```
normalization_layer = layers.Rescaling(1./255)

normalized_ds = ds_train.map(lambda x, y: (normalization_layer(x), y))
image_batch, labels_batch = next(iter(normalized_ds))
first_image = image_batch[0]
```

### Create and train the model
Create the model:
```
num_classes = 3

model = Sequential([
  layers.Rescaling(1./255),
  layers.Conv2D(16, 3, padding='same', activation='relu'),
  layers.MaxPooling2D(),
  layers.Conv2D(32, 3, padding='same', activation='relu'),
  layers.MaxPooling2D(),
  layers.Conv2D(64, 3, padding='same', activation='relu'),
  layers.MaxPooling2D(),
  layers.Flatten(),
  layers.Dense(128, activation='relu'),
  layers.Dense(num_classes)
])
```
Compile the model:
```
model.compile(optimizer='adam',
              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics=['accuracy'])
```
Train the model:
```
epochs = 15
history = model.fit(
  ds_train,
  validation_data=ds_val,
  epochs=epochs
)
```
```
>>> Epoch 1/15
26/26 [==============================] - 12s 431ms/step - loss: 0.8700 - accuracy: 0.6691 - val_loss: 0.4710 - val_accuracy: 0.8030
Epoch 2/15
26/26 [==============================] - 11s 418ms/step - loss: 0.4397 - accuracy: 0.8284 - val_loss: 0.3703 - val_accuracy: 0.8621
Epoch 3/15
26/26 [==============================] - 11s 420ms/step - loss: 0.3177 - accuracy: 0.8701 - val_loss: 0.3537 - val_accuracy: 0.8571
Epoch 4/15
26/26 [==============================] - 11s 413ms/step - loss: 0.2421 - accuracy: 0.9216 - val_loss: 0.2879 - val_accuracy: 0.8818
Epoch 5/15
26/26 [==============================] - 11s 416ms/step - loss: 0.1753 - accuracy: 0.9400 - val_loss: 0.2991 - val_accuracy: 0.8571
Epoch 6/15
26/26 [==============================] - 11s 419ms/step - loss: 0.1253 - accuracy: 0.9534 - val_loss: 0.2927 - val_accuracy: 0.8916
Epoch 7/15
26/26 [==============================] - 11s 418ms/step - loss: 0.0723 - accuracy: 0.9706 - val_loss: 0.2974 - val_accuracy: 0.9015
Epoch 8/15
26/26 [==============================] - 11s 421ms/step - loss: 0.0571 - accuracy: 0.9853 - val_loss: 0.3005 - val_accuracy: 0.9015
Epoch 9/15
26/26 [==============================] - 11s 421ms/step - loss: 0.0435 - accuracy: 0.9902 - val_loss: 0.2718 - val_accuracy: 0.8966
Epoch 10/15
26/26 [==============================] - 11s 414ms/step - loss: 0.0340 - accuracy: 0.9939 - val_loss: 0.4238 - val_accuracy: 0.8818
Epoch 11/15
26/26 [==============================] - 11s 429ms/step - loss: 0.0681 - accuracy: 0.9755 - val_loss: 0.3822 - val_accuracy: 0.8768
Epoch 12/15
26/26 [==============================] - 11s 418ms/step - loss: 0.0371 - accuracy: 0.9902 - val_loss: 0.2398 - val_accuracy: 0.9113
Epoch 13/15
26/26 [==============================] - 11s 421ms/step - loss: 0.0149 - accuracy: 0.9988 - val_loss: 0.3003 - val_accuracy: 0.9064
Epoch 14/15
26/26 [==============================] - 11s 421ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.3472 - val_accuracy: 0.9015
Epoch 15/15
26/26 [==============================] - 11s 418ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.3427 - val_accuracy: 0.8916
```
Summary of the model:
```
model.summary()
```
```
>>> Model: "sequential"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 rescaling_1 (Rescaling)     (None, 180, 180, 3)       0         
                                                                 
 conv2d (Conv2D)             (None, 180, 180, 16)      448       
                                                                 
 max_pooling2d (MaxPooling2D  (None, 90, 90, 16)       0         
 )                                                               
                                                                 
 conv2d_1 (Conv2D)           (None, 90, 90, 32)        4640      
                                                                 
 max_pooling2d_1 (MaxPooling  (None, 45, 45, 32)       0         
 2D)                                                             
                                                                 
 conv2d_2 (Conv2D)           (None, 45, 45, 64)        18496     
                                                                 
 max_pooling2d_2 (MaxPooling  (None, 22, 22, 64)       0         
 2D)                                                             
                                                                 
 flatten (Flatten)           (None, 30976)             0         
                                                                 
 dense (Dense)               (None, 128)               3965056   
                                                                 
 dense_1 (Dense)             (None, 3)                 387       
                                                                 
=================================================================
Total params: 3,989,027
Trainable params: 3,989,027
Non-trainable params: 0
_________________________________________________________________
```
Results of the training set:
```
fig, axes = plt.subplots(1,2,figsize=(12, 4))
for ax, measure in zip(axes, ['loss', 'accuracy']):
    ax.plot(history.history[measure], label=measure)
    ax.plot(history.history['val_' + measure], label='val_' + measure)
    ax.legend()
pass
```
![Image 2](/v_source/hw5-2.png)

### Evaluate test results
```
x_train = np.concatenate([x for x, y in ds_train], axis = 0)
y_train = np.concatenate([y for x, y in ds_train], axis = 0)
x_test = np.concatenate([x for x, y in ds_test], axis = 0)
y_test = np.concatenate([y for x, y in ds_test], axis = 0)
```
Evaluate test loss and accuracy:
```
score = model.evaluate(x_test, y_test, batch_size=128)
print(f'Test loss: {score[0]}, Test accuracy: {score[1]}')
```
```
>>> 2/2 [==============================] - 1s 168ms/step - loss: 11.5229 - accuracy: 0.2667
Test loss: 11.522893905639648, Test accuracy: 0.2666666805744171
```
Select one image to test:
```
p_path = 'insects/test/dragonflies/5402441.jpg'

img_p = PIL.Image.open(p_path)
plt.imshow(img_p)
plt.show()

img = tf.keras.utils.load_img(
    p_path, target_size=(img_height, img_width)
)
img_array = tf.keras.utils.img_to_array(img)
img_array = tf.expand_dims(img_array, 0) # Create a batch

predictions = model.predict(img_array)
score = tf.nn.softmax(predictions[0])

print(
    "This image most likely belongs to {} with a {:.2f} percent confidence.".format(class_names[np.argmax(score)], 100 * np.max(score))
)
```
![Image 3](/v_source/hw5-3.png)

### SHapley Additive exPlanations
```
explainer = shap.GradientExplainer(model, x_train)
sv = explainer.shap_values(x_test[:10])
shap.image_plot([sv[i] for i in range(3)], x_test[:10])
```
![Image 4](/v_source/hw5-4.png)
